{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 573 - Feature and Model Selection\n",
    "\n",
    "# Lab 4: A mini project - Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Submission instructions](#si) (4%)\n",
    "1. [Understanding the problem](#1) (4%)\n",
    "2. [Data splitting](#2) (2%)\n",
    "3. [EDA](#3) (10%)\n",
    "4. (Optional) [Feature engineering](#4)\n",
    "5. [Preprocessing and transformations](#5) (10%)\n",
    "6. [Baseline model](#6) (2%)\n",
    "7. [Linear models](#7) (10%)\n",
    "8. [Different models](#8) (16%)\n",
    "9. (Optional) [Feature selection](#9)\n",
    "10. [Hyperparameter optimization](#10) (10%)\n",
    "11. [Interpretation and feature importances](#11) (10%)\n",
    "12. [Results on the test set](#12) (10%)\n",
    "13. [Summary of the results](#13) (12%)\n",
    "15. (Optional) [Reproducible data analysis pipeline](#14)\n",
    "15. (Optional) [Your takeaway from the course](#15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={mechanics:4}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **Which problem did you pick, classification or regression? Classification**\n",
    "- **Report your test score here along with the metric used:** \n",
    "- **Please add a link to your GitHub repository here: https://github.com/nobbynguyen/573Lab4_Classification_Group_GSN** \n",
    "- **You don't have to but you may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4. \n",
    "    - You can choose your own group members. Since I don't know your groups in advance, I am not opening this lab as a group lab. So you all will have a separate GitHub repository for your labs and you'll have to decide how you want to collaborate. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. [Here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members) are some instructions on adding group members in Gradescope.  \n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- Make at least three commits in your lab's GitHub repository.\n",
    "- Push the final .ipynb file with your solutions to your GitHub repository for this lab.\n",
    "- Upload the .ipynb file to Gradescope.\n",
    "- If the .ipynb file is too big or doesn't render on Gradescope for some reason, also upload a pdf or html in addition to the .ipynb. \n",
    "- Make sure that your plots/output are rendered properly in Gradescope.\n",
    "\n",
    "> [Here](https://github.com/UBC-MDS/public/tree/master/rubric) you will find the description of each rubric used in MDS.\n",
    "\n",
    "> As usual, do not push the data to the repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "In this lab you will be working on an open-ended mini-project, where you will put all the different things you have learned so far in 571 and 573 together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "\n",
    "#### A final note\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-8 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pick your problem and explain what exactly you are trying to predict <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:4}\n",
    "\n",
    "In this mini project, you will pick one of the following problems: \n",
    "\n",
    "- A classification problem of predicting whether a credit card client will default or not. For this problem, you will use [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). In this data set, there are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default.payment.next.month\" in the data. The rest of the columns can be used as features. You may take some ideas and compare your results with [the associated research paper](https://www.sciencedirect.com/science/article/pii/S0957417407006719), which is available through [the UBC library](https://www.library.ubc.ca/). \n",
    "\n",
    "OR \n",
    "\n",
    "- A regression problem of predicting `reviews_per_month`, as a proxy for the popularity of the listing with [New York City Airbnb listings from 2019 dataset](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data). Airbnb could use this sort of model to predict how popular future listings might be before they are posted, perhaps to help guide hosts create more appealing listings. In reality they might instead use something like vacancy rate or average rating as their target, but we do not have that available here.\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. \n",
    "3. Carry out any preliminary preprocessing, if needed (e.g., changing feature names, handling of NaN values etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 - Answer**:\n",
    "- The data set is about credit transactions of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "- The problem is to predict whether a credit card client will default (fail to pay) the credit card bills.\n",
    "- The target column is `default.payment.next.month` with 2 values: 1 = yes, 0 = no. \n",
    "- The following 23 features can be used as explanatory variables:\n",
    "    - LIMIT_BAL: Amount of the given credit (NT dollar)\n",
    "    - SEX: Gender (1 = male, 2 = female)\n",
    "    - EDUCATION: Education level (1 = graduate school, 2 = university, 3 = high school, 4 = others, 5 or 6 = unknown)\n",
    "    - MARRIAGE: Marital status (1 = married, 2 = single, 3 = others)\n",
    "    - AGE: Age (years)\n",
    "    - PAY_0 – PAY_6: Status of past monthly payment (-1 = pay duly, 1 = payment delay for one month,..., 9 = payment delay for nine months and above), where PAY_0 = repayment status in September 2005,..., PAY_6 = repayment status in April 2005. \n",
    "    - BILL_AMT1 – BILL_AMT6: Amount of bill statement (NT dollar) from September 2005 to April 2005, respectively.\n",
    "    - PAY_AMT1 – PAY_AMT6: Amount of previous statement (NT dollar) from September 2005 to April 2005, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0          1    20000.0    2          2         1   24      2      2     -1   \n",
       "1          2   120000.0    2          2         2   26     -1      2      0   \n",
       "2          3    90000.0    2          2         2   34      0      0      0   \n",
       "3          4    50000.0    2          2         1   37      0      0      0   \n",
       "4          5    50000.0    1          2         1   57     -1      0     -1   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "29995  29996   220000.0    1          3         1   39      0      0      0   \n",
       "29996  29997   150000.0    1          3         2   43     -1     -1     -1   \n",
       "29997  29998    30000.0    1          2         2   37      4      3      2   \n",
       "29998  29999    80000.0    1          3         1   41      1     -1      0   \n",
       "29999  30000    50000.0    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -1  ...        0.0        0.0        0.0       0.0     689.0   \n",
       "1          0  ...     3272.0     3455.0     3261.0       0.0    1000.0   \n",
       "2          0  ...    14331.0    14948.0    15549.0    1518.0    1500.0   \n",
       "3          0  ...    28314.0    28959.0    29547.0    2000.0    2019.0   \n",
       "4          0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...    88004.0    31237.0    15980.0    8500.0   20000.0   \n",
       "29996     -1  ...     8979.0     5190.0        0.0    1837.0    3526.0   \n",
       "29997     -1  ...    20878.0    20582.0    19357.0       0.0       0.0   \n",
       "29998      0  ...    52774.0    11855.0    48944.0   85900.0    3409.0   \n",
       "29999      0  ...    36535.0    32428.0    15313.0    2078.0    1800.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0           0.0       0.0       0.0       0.0                           1  \n",
       "1        1000.0    1000.0       0.0    2000.0                           1  \n",
       "2        1000.0    1000.0    1000.0    5000.0                           0  \n",
       "3        1200.0    1100.0    1069.0    1000.0                           0  \n",
       "4       10000.0    9000.0     689.0     679.0                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29995    5003.0    3047.0    5000.0    1000.0                           0  \n",
       "29996    8998.0     129.0       0.0       0.0                           0  \n",
       "29997   22000.0    4200.0    2000.0    3100.0                           1  \n",
       "29998    1178.0    1926.0   52964.0    1804.0                           1  \n",
       "29999    1430.0    1000.0    1000.0    1000.0                           1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Read in the data\n",
    "credit_card_df = pd.read_csv(\"UCI_Credit_Card.csv\")\n",
    "credit_card_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 - Answer**: There are no missing values in the data set, data types are appropriate, and feature names are quite standard (except `PAY_0`). Hence, there is no need to do any preliminary preprocessing, except renaming column `PAY_0` to `PAY_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          30000 non-null  int64  \n",
      " 1   LIMIT_BAL                   30000 non-null  float64\n",
      " 2   SEX                         30000 non-null  int64  \n",
      " 3   EDUCATION                   30000 non-null  int64  \n",
      " 4   MARRIAGE                    30000 non-null  int64  \n",
      " 5   AGE                         30000 non-null  int64  \n",
      " 6   PAY_0                       30000 non-null  int64  \n",
      " 7   PAY_2                       30000 non-null  int64  \n",
      " 8   PAY_3                       30000 non-null  int64  \n",
      " 9   PAY_4                       30000 non-null  int64  \n",
      " 10  PAY_5                       30000 non-null  int64  \n",
      " 11  PAY_6                       30000 non-null  int64  \n",
      " 12  BILL_AMT1                   30000 non-null  float64\n",
      " 13  BILL_AMT2                   30000 non-null  float64\n",
      " 14  BILL_AMT3                   30000 non-null  float64\n",
      " 15  BILL_AMT4                   30000 non-null  float64\n",
      " 16  BILL_AMT5                   30000 non-null  float64\n",
      " 17  BILL_AMT6                   30000 non-null  float64\n",
      " 18  PAY_AMT1                    30000 non-null  float64\n",
      " 19  PAY_AMT2                    30000 non-null  float64\n",
      " 20  PAY_AMT3                    30000 non-null  float64\n",
      " 21  PAY_AMT4                    30000 non-null  float64\n",
      " 22  PAY_AMT5                    30000 non-null  float64\n",
      " 23  PAY_AMT6                    30000 non-null  float64\n",
      " 24  default.payment.next.month  30000 non-null  int64  \n",
      "dtypes: float64(13), int64(12)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "credit_card_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  \\\n",
       "0          1    20000.0    2          2         1   24      2      2     -1   \n",
       "1          2   120000.0    2          2         2   26     -1      2      0   \n",
       "2          3    90000.0    2          2         2   34      0      0      0   \n",
       "3          4    50000.0    2          2         1   37      0      0      0   \n",
       "4          5    50000.0    1          2         1   57     -1      0     -1   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "29995  29996   220000.0    1          3         1   39      0      0      0   \n",
       "29996  29997   150000.0    1          3         2   43     -1     -1     -1   \n",
       "29997  29998    30000.0    1          2         2   37      4      3      2   \n",
       "29998  29999    80000.0    1          3         1   41      1     -1      0   \n",
       "29999  30000    50000.0    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -1  ...        0.0        0.0        0.0       0.0     689.0   \n",
       "1          0  ...     3272.0     3455.0     3261.0       0.0    1000.0   \n",
       "2          0  ...    14331.0    14948.0    15549.0    1518.0    1500.0   \n",
       "3          0  ...    28314.0    28959.0    29547.0    2000.0    2019.0   \n",
       "4          0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...    88004.0    31237.0    15980.0    8500.0   20000.0   \n",
       "29996     -1  ...     8979.0     5190.0        0.0    1837.0    3526.0   \n",
       "29997     -1  ...    20878.0    20582.0    19357.0       0.0       0.0   \n",
       "29998      0  ...    52774.0    11855.0    48944.0   85900.0    3409.0   \n",
       "29999      0  ...    36535.0    32428.0    15313.0    2078.0    1800.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0           0.0       0.0       0.0       0.0                           1  \n",
       "1        1000.0    1000.0       0.0    2000.0                           1  \n",
       "2        1000.0    1000.0    1000.0    5000.0                           0  \n",
       "3        1200.0    1100.0    1069.0    1000.0                           0  \n",
       "4       10000.0    9000.0     689.0     679.0                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29995    5003.0    3047.0    5000.0    1000.0                           0  \n",
       "29996    8998.0     129.0       0.0       0.0                           0  \n",
       "29997   22000.0    4200.0    2000.0    3100.0                           1  \n",
       "29998    1178.0    1926.0   52964.0    1804.0                           1  \n",
       "29999    1430.0    1000.0    1000.0    1000.0                           1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df = credit_card_df.rename(columns={\"PAY_0\": \"PAY_1\"})\n",
    "credit_card_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train and test portions.\n",
    "\n",
    "> Make decision on the `test_size` based on the capacity of your laptop. Don't forget to use a random state.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(credit_card_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16395</th>\n",
       "      <td>16396</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19370.0</td>\n",
       "      <td>10155.0</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7013.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>21449</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>171244.0</td>\n",
       "      <td>150897.0</td>\n",
       "      <td>117870.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>87426.0</td>\n",
       "      <td>130007.0</td>\n",
       "      <td>3018.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>51663.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>20035</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25755</th>\n",
       "      <td>25756</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103058.0</td>\n",
       "      <td>71095.0</td>\n",
       "      <td>47379.0</td>\n",
       "      <td>3706.0</td>\n",
       "      <td>5502.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>3017.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1439</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27585.0</td>\n",
       "      <td>27910.0</td>\n",
       "      <td>27380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "16395  16396   320000.0    2          1         2   36      0      0      0   \n",
       "21448  21449   440000.0    2          1         2   30     -1     -1     -1   \n",
       "20034  20035   160000.0    2          3         1   44     -2     -2     -2   \n",
       "25755  25756   120000.0    2          2         1   30      0      0      0   \n",
       "1438    1439    50000.0    1          2         2   54      1      2      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "16395      0  ...    19370.0    10155.0     3788.0    5000.0    5018.0   \n",
       "21448      0  ...   171244.0   150897.0   117870.0     612.0   87426.0   \n",
       "20034     -2  ...      -18.0      -18.0      -18.0       0.0       0.0   \n",
       "25755      0  ...   103058.0    71095.0    47379.0    3706.0    5502.0   \n",
       "1438       0  ...    27585.0    27910.0    27380.0       0.0    1400.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "16395    1000.0    3000.0       0.0    7013.0                           0  \n",
       "21448  130007.0    3018.0   15000.0   51663.0                           0  \n",
       "20034       0.0       0.0       0.0       0.0                           0  \n",
       "25755    4204.0    3017.0    2005.0    1702.0                           0  \n",
       "1438     1200.0    1500.0    1000.0    1500.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 25)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=[\"default.payment.next.month\"]), train_df[\"default.payment.next.month\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"default.payment.next.month\"]), test_df[\"default.payment.next.month\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "rubric={viz:4,reasoning:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.776762\n",
       "1    0.223238\n",
       "Name: default.payment.next.month, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. EDA\n",
    "train_df[\"default.payment.next.month\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is class imbalance. Only around 22% of the examples in the training set belong to the \"default\" class, which is of our interest. We are likely to be interested in finding default customers so that the bank can stop offering them credit lines and so predicting \"True\" examples correctly is more important to us.\n",
    "Therefore, we decided to choose classification metrics recall, precision, f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028419</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>-0.024071</td>\n",
       "      <td>0.021795</td>\n",
       "      <td>-0.029574</td>\n",
       "      <td>-0.011899</td>\n",
       "      <td>-0.017471</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042005</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.019477</td>\n",
       "      <td>0.013488</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>0.036544</td>\n",
       "      <td>0.010153</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>-0.017861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <td>0.028419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>-0.223207</td>\n",
       "      <td>-0.115202</td>\n",
       "      <td>0.146419</td>\n",
       "      <td>-0.271686</td>\n",
       "      <td>-0.299924</td>\n",
       "      <td>-0.289222</td>\n",
       "      <td>-0.269399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297468</td>\n",
       "      <td>0.299353</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>0.191669</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.206416</td>\n",
       "      <td>0.204308</td>\n",
       "      <td>0.215244</td>\n",
       "      <td>0.215337</td>\n",
       "      <td>-0.149247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>0.019014</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>-0.033413</td>\n",
       "      <td>-0.091890</td>\n",
       "      <td>-0.061038</td>\n",
       "      <td>-0.073214</td>\n",
       "      <td>-0.068192</td>\n",
       "      <td>-0.063772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022471</td>\n",
       "      <td>-0.015973</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.008136</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>-0.004470</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>-0.046320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <td>0.040633</td>\n",
       "      <td>-0.223207</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.142499</td>\n",
       "      <td>0.175042</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>0.125907</td>\n",
       "      <td>0.118096</td>\n",
       "      <td>0.110732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>-0.005203</td>\n",
       "      <td>-0.005595</td>\n",
       "      <td>-0.039769</td>\n",
       "      <td>-0.028295</td>\n",
       "      <td>-0.039621</td>\n",
       "      <td>-0.038918</td>\n",
       "      <td>-0.031589</td>\n",
       "      <td>-0.038563</td>\n",
       "      <td>0.026558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE</th>\n",
       "      <td>-0.024071</td>\n",
       "      <td>-0.115202</td>\n",
       "      <td>-0.033413</td>\n",
       "      <td>-0.142499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.414446</td>\n",
       "      <td>0.016416</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028532</td>\n",
       "      <td>-0.031878</td>\n",
       "      <td>-0.027376</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>-0.005287</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>-0.014206</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>-0.007532</td>\n",
       "      <td>-0.021735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.021795</td>\n",
       "      <td>0.146419</td>\n",
       "      <td>-0.091890</td>\n",
       "      <td>0.175042</td>\n",
       "      <td>-0.414446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032232</td>\n",
       "      <td>-0.045343</td>\n",
       "      <td>-0.050597</td>\n",
       "      <td>-0.047465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.059023</td>\n",
       "      <td>0.058003</td>\n",
       "      <td>0.023255</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>0.017527</td>\n",
       "      <td>0.010715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_0</th>\n",
       "      <td>-0.029574</td>\n",
       "      <td>-0.271686</td>\n",
       "      <td>-0.061038</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>0.016416</td>\n",
       "      <td>-0.032232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670967</td>\n",
       "      <td>0.571947</td>\n",
       "      <td>0.534071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172808</td>\n",
       "      <td>0.175548</td>\n",
       "      <td>0.173661</td>\n",
       "      <td>-0.076790</td>\n",
       "      <td>-0.071744</td>\n",
       "      <td>-0.074217</td>\n",
       "      <td>-0.065880</td>\n",
       "      <td>-0.053086</td>\n",
       "      <td>-0.063282</td>\n",
       "      <td>0.325102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_2</th>\n",
       "      <td>-0.011899</td>\n",
       "      <td>-0.299924</td>\n",
       "      <td>-0.073214</td>\n",
       "      <td>0.125907</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>-0.045343</td>\n",
       "      <td>0.670967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.770190</td>\n",
       "      <td>0.664641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218033</td>\n",
       "      <td>0.216657</td>\n",
       "      <td>0.216919</td>\n",
       "      <td>-0.076280</td>\n",
       "      <td>-0.057781</td>\n",
       "      <td>-0.055477</td>\n",
       "      <td>-0.052057</td>\n",
       "      <td>-0.033231</td>\n",
       "      <td>-0.039994</td>\n",
       "      <td>0.265160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_3</th>\n",
       "      <td>-0.017471</td>\n",
       "      <td>-0.289222</td>\n",
       "      <td>-0.068192</td>\n",
       "      <td>0.118096</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>-0.050597</td>\n",
       "      <td>0.571947</td>\n",
       "      <td>0.770190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221998</td>\n",
       "      <td>0.219870</td>\n",
       "      <td>0.218656</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>-0.068541</td>\n",
       "      <td>-0.054288</td>\n",
       "      <td>-0.052475</td>\n",
       "      <td>-0.035079</td>\n",
       "      <td>-0.043431</td>\n",
       "      <td>0.240503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_4</th>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-0.269399</td>\n",
       "      <td>-0.063772</td>\n",
       "      <td>0.110732</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>-0.047465</td>\n",
       "      <td>0.534071</td>\n",
       "      <td>0.664641</td>\n",
       "      <td>0.779639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240648</td>\n",
       "      <td>0.236905</td>\n",
       "      <td>0.234309</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>-0.069715</td>\n",
       "      <td>-0.048923</td>\n",
       "      <td>-0.032754</td>\n",
       "      <td>-0.028226</td>\n",
       "      <td>0.219692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_5</th>\n",
       "      <td>-0.022719</td>\n",
       "      <td>-0.249030</td>\n",
       "      <td>-0.055062</td>\n",
       "      <td>0.101603</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>-0.050073</td>\n",
       "      <td>0.504219</td>\n",
       "      <td>0.622672</td>\n",
       "      <td>0.685032</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265262</td>\n",
       "      <td>0.263856</td>\n",
       "      <td>0.257387</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>-0.058547</td>\n",
       "      <td>-0.032159</td>\n",
       "      <td>-0.025219</td>\n",
       "      <td>0.208726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6</th>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.236218</td>\n",
       "      <td>-0.041594</td>\n",
       "      <td>0.088186</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>-0.041689</td>\n",
       "      <td>0.470939</td>\n",
       "      <td>0.575450</td>\n",
       "      <td>0.631932</td>\n",
       "      <td>0.713851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262129</td>\n",
       "      <td>0.287259</td>\n",
       "      <td>0.282981</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>-0.045211</td>\n",
       "      <td>-0.029144</td>\n",
       "      <td>0.194787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.283635</td>\n",
       "      <td>-0.035212</td>\n",
       "      <td>0.026108</td>\n",
       "      <td>-0.027264</td>\n",
       "      <td>0.064703</td>\n",
       "      <td>0.186433</td>\n",
       "      <td>0.235992</td>\n",
       "      <td>0.207658</td>\n",
       "      <td>0.201714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861671</td>\n",
       "      <td>0.830888</td>\n",
       "      <td>0.805667</td>\n",
       "      <td>0.146775</td>\n",
       "      <td>0.108425</td>\n",
       "      <td>0.150079</td>\n",
       "      <td>0.150477</td>\n",
       "      <td>0.172609</td>\n",
       "      <td>0.170210</td>\n",
       "      <td>-0.020632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.277334</td>\n",
       "      <td>-0.031960</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>-0.024688</td>\n",
       "      <td>0.061367</td>\n",
       "      <td>0.187401</td>\n",
       "      <td>0.236222</td>\n",
       "      <td>0.235810</td>\n",
       "      <td>0.224515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892482</td>\n",
       "      <td>0.858302</td>\n",
       "      <td>0.832519</td>\n",
       "      <td>0.282783</td>\n",
       "      <td>0.113772</td>\n",
       "      <td>0.146473</td>\n",
       "      <td>0.139343</td>\n",
       "      <td>0.165163</td>\n",
       "      <td>0.169213</td>\n",
       "      <td>-0.015301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <td>0.028270</td>\n",
       "      <td>0.283969</td>\n",
       "      <td>-0.023333</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>-0.029866</td>\n",
       "      <td>0.062484</td>\n",
       "      <td>0.179065</td>\n",
       "      <td>0.226122</td>\n",
       "      <td>0.227556</td>\n",
       "      <td>0.245064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931703</td>\n",
       "      <td>0.892319</td>\n",
       "      <td>0.858671</td>\n",
       "      <td>0.252786</td>\n",
       "      <td>0.285372</td>\n",
       "      <td>0.119375</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>0.180129</td>\n",
       "      <td>-0.014718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <td>0.042005</td>\n",
       "      <td>0.297468</td>\n",
       "      <td>-0.022471</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>-0.028532</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.172808</td>\n",
       "      <td>0.218033</td>\n",
       "      <td>0.221998</td>\n",
       "      <td>0.240648</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941142</td>\n",
       "      <td>0.902447</td>\n",
       "      <td>0.243395</td>\n",
       "      <td>0.223203</td>\n",
       "      <td>0.298209</td>\n",
       "      <td>0.138020</td>\n",
       "      <td>0.166755</td>\n",
       "      <td>0.169249</td>\n",
       "      <td>-0.012313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.299353</td>\n",
       "      <td>-0.015973</td>\n",
       "      <td>-0.005203</td>\n",
       "      <td>-0.031878</td>\n",
       "      <td>0.059023</td>\n",
       "      <td>0.175548</td>\n",
       "      <td>0.216657</td>\n",
       "      <td>0.219870</td>\n",
       "      <td>0.236905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941142</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944748</td>\n",
       "      <td>0.227985</td>\n",
       "      <td>0.199445</td>\n",
       "      <td>0.248918</td>\n",
       "      <td>0.292033</td>\n",
       "      <td>0.149058</td>\n",
       "      <td>0.156680</td>\n",
       "      <td>-0.007868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <td>0.019477</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>-0.005595</td>\n",
       "      <td>-0.027376</td>\n",
       "      <td>0.058003</td>\n",
       "      <td>0.173661</td>\n",
       "      <td>0.216919</td>\n",
       "      <td>0.218656</td>\n",
       "      <td>0.234309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902447</td>\n",
       "      <td>0.944748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211163</td>\n",
       "      <td>0.175053</td>\n",
       "      <td>0.230284</td>\n",
       "      <td>0.244266</td>\n",
       "      <td>0.309427</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>-0.004944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <td>0.013488</td>\n",
       "      <td>0.191669</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>-0.039769</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>0.023255</td>\n",
       "      <td>-0.076790</td>\n",
       "      <td>-0.076280</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243395</td>\n",
       "      <td>0.227985</td>\n",
       "      <td>0.211163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359611</td>\n",
       "      <td>0.263792</td>\n",
       "      <td>0.217311</td>\n",
       "      <td>0.147038</td>\n",
       "      <td>0.177324</td>\n",
       "      <td>-0.071563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <td>0.013389</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.028295</td>\n",
       "      <td>-0.005287</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>-0.071744</td>\n",
       "      <td>-0.057781</td>\n",
       "      <td>-0.068541</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223203</td>\n",
       "      <td>0.199445</td>\n",
       "      <td>0.175053</td>\n",
       "      <td>0.359611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268024</td>\n",
       "      <td>0.212814</td>\n",
       "      <td>0.134298</td>\n",
       "      <td>0.173510</td>\n",
       "      <td>-0.060730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <td>0.036544</td>\n",
       "      <td>0.206416</td>\n",
       "      <td>-0.008136</td>\n",
       "      <td>-0.039621</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>-0.074217</td>\n",
       "      <td>-0.055477</td>\n",
       "      <td>-0.054288</td>\n",
       "      <td>-0.069715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298209</td>\n",
       "      <td>0.248918</td>\n",
       "      <td>0.230284</td>\n",
       "      <td>0.263792</td>\n",
       "      <td>0.268024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224648</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>0.146699</td>\n",
       "      <td>-0.060868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <td>0.010153</td>\n",
       "      <td>0.204308</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>-0.038918</td>\n",
       "      <td>-0.014206</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>-0.065880</td>\n",
       "      <td>-0.052057</td>\n",
       "      <td>-0.052475</td>\n",
       "      <td>-0.048923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138020</td>\n",
       "      <td>0.292033</td>\n",
       "      <td>0.244266</td>\n",
       "      <td>0.217311</td>\n",
       "      <td>0.212814</td>\n",
       "      <td>0.224648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>-0.061005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.215244</td>\n",
       "      <td>-0.004470</td>\n",
       "      <td>-0.031589</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>-0.053086</td>\n",
       "      <td>-0.033231</td>\n",
       "      <td>-0.035079</td>\n",
       "      <td>-0.032754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166755</td>\n",
       "      <td>0.149058</td>\n",
       "      <td>0.309427</td>\n",
       "      <td>0.147038</td>\n",
       "      <td>0.134298</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141182</td>\n",
       "      <td>-0.050943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.215337</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>-0.038563</td>\n",
       "      <td>-0.007532</td>\n",
       "      <td>0.017527</td>\n",
       "      <td>-0.063282</td>\n",
       "      <td>-0.039994</td>\n",
       "      <td>-0.043431</td>\n",
       "      <td>-0.028226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.156680</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.177324</td>\n",
       "      <td>0.173510</td>\n",
       "      <td>0.146699</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>0.141182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default.payment.next.month</th>\n",
       "      <td>-0.017861</td>\n",
       "      <td>-0.149247</td>\n",
       "      <td>-0.046320</td>\n",
       "      <td>0.026558</td>\n",
       "      <td>-0.021735</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.325102</td>\n",
       "      <td>0.265160</td>\n",
       "      <td>0.240503</td>\n",
       "      <td>0.219692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012313</td>\n",
       "      <td>-0.007868</td>\n",
       "      <td>-0.004944</td>\n",
       "      <td>-0.071563</td>\n",
       "      <td>-0.060730</td>\n",
       "      <td>-0.060868</td>\n",
       "      <td>-0.061005</td>\n",
       "      <td>-0.050943</td>\n",
       "      <td>-0.056093</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ID  LIMIT_BAL       SEX  EDUCATION  \\\n",
       "ID                          1.000000   0.028419  0.019014   0.040633   \n",
       "LIMIT_BAL                   0.028419   1.000000  0.027466  -0.223207   \n",
       "SEX                         0.019014   0.027466  1.000000   0.012307   \n",
       "EDUCATION                   0.040633  -0.223207  0.012307   1.000000   \n",
       "MARRIAGE                   -0.024071  -0.115202 -0.033413  -0.142499   \n",
       "AGE                         0.021795   0.146419 -0.091890   0.175042   \n",
       "PAY_0                      -0.029574  -0.271686 -0.061038   0.111222   \n",
       "PAY_2                      -0.011899  -0.299924 -0.073214   0.125907   \n",
       "PAY_3                      -0.017471  -0.289222 -0.068192   0.118096   \n",
       "PAY_4                      -0.000293  -0.269399 -0.063772   0.110732   \n",
       "PAY_5                      -0.022719  -0.249030 -0.055062   0.101603   \n",
       "PAY_6                      -0.022829  -0.236218 -0.041594   0.088186   \n",
       "BILL_AMT1                   0.020447   0.283635 -0.035212   0.026108   \n",
       "BILL_AMT2                   0.019669   0.277334 -0.031960   0.020668   \n",
       "BILL_AMT3                   0.028270   0.283969 -0.023333   0.016967   \n",
       "BILL_AMT4                   0.042005   0.297468 -0.022471   0.003286   \n",
       "BILL_AMT5                   0.020323   0.299353 -0.015973  -0.005203   \n",
       "BILL_AMT6                   0.019477   0.293757 -0.015158  -0.005595   \n",
       "PAY_AMT1                    0.013488   0.191669  0.001324  -0.039769   \n",
       "PAY_AMT2                    0.013389   0.183705  0.000908  -0.028295   \n",
       "PAY_AMT3                    0.036544   0.206416 -0.008136  -0.039621   \n",
       "PAY_AMT4                    0.010153   0.204308  0.001473  -0.038918   \n",
       "PAY_AMT5                   -0.000093   0.215244 -0.004470  -0.031589   \n",
       "PAY_AMT6                    0.001252   0.215337 -0.001600  -0.038563   \n",
       "default.payment.next.month -0.017861  -0.149247 -0.046320   0.026558   \n",
       "\n",
       "                            MARRIAGE       AGE     PAY_0     PAY_2     PAY_3  \\\n",
       "ID                         -0.024071  0.021795 -0.029574 -0.011899 -0.017471   \n",
       "LIMIT_BAL                  -0.115202  0.146419 -0.271686 -0.299924 -0.289222   \n",
       "SEX                        -0.033413 -0.091890 -0.061038 -0.073214 -0.068192   \n",
       "EDUCATION                  -0.142499  0.175042  0.111222  0.125907  0.118096   \n",
       "MARRIAGE                    1.000000 -0.414446  0.016416  0.023994  0.035001   \n",
       "AGE                        -0.414446  1.000000 -0.032232 -0.045343 -0.050597   \n",
       "PAY_0                       0.016416 -0.032232  1.000000  0.670967  0.571947   \n",
       "PAY_2                       0.023994 -0.045343  0.670967  1.000000  0.770190   \n",
       "PAY_3                       0.035001 -0.050597  0.571947  0.770190  1.000000   \n",
       "PAY_4                       0.031905 -0.047465  0.534071  0.664641  0.779639   \n",
       "PAY_5                       0.035830 -0.050073  0.504219  0.622672  0.685032   \n",
       "PAY_6                       0.029353 -0.041689  0.470939  0.575450  0.631932   \n",
       "BILL_AMT1                  -0.027264  0.064703  0.186433  0.235992  0.207658   \n",
       "BILL_AMT2                  -0.024688  0.061367  0.187401  0.236222  0.235810   \n",
       "BILL_AMT3                  -0.029866  0.062484  0.179065  0.226122  0.227556   \n",
       "BILL_AMT4                  -0.028532  0.061071  0.172808  0.218033  0.221998   \n",
       "BILL_AMT5                  -0.031878  0.059023  0.175548  0.216657  0.219870   \n",
       "BILL_AMT6                  -0.027376  0.058003  0.173661  0.216919  0.218656   \n",
       "PAY_AMT1                   -0.001337  0.023255 -0.076790 -0.076280  0.002073   \n",
       "PAY_AMT2                   -0.005287  0.023572 -0.071744 -0.057781 -0.068541   \n",
       "PAY_AMT3                   -0.002401  0.034136 -0.074217 -0.055477 -0.054288   \n",
       "PAY_AMT4                   -0.014206  0.025197 -0.065880 -0.052057 -0.052475   \n",
       "PAY_AMT5                   -0.000819  0.028544 -0.053086 -0.033231 -0.035079   \n",
       "PAY_AMT6                   -0.007532  0.017527 -0.063282 -0.039994 -0.043431   \n",
       "default.payment.next.month -0.021735  0.010715  0.325102  0.265160  0.240503   \n",
       "\n",
       "                               PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  \\\n",
       "ID                         -0.000293  ...   0.042005   0.020323   0.019477   \n",
       "LIMIT_BAL                  -0.269399  ...   0.297468   0.299353   0.293757   \n",
       "SEX                        -0.063772  ...  -0.022471  -0.015973  -0.015158   \n",
       "EDUCATION                   0.110732  ...   0.003286  -0.005203  -0.005595   \n",
       "MARRIAGE                    0.031905  ...  -0.028532  -0.031878  -0.027376   \n",
       "AGE                        -0.047465  ...   0.061071   0.059023   0.058003   \n",
       "PAY_0                       0.534071  ...   0.172808   0.175548   0.173661   \n",
       "PAY_2                       0.664641  ...   0.218033   0.216657   0.216919   \n",
       "PAY_3                       0.779639  ...   0.221998   0.219870   0.218656   \n",
       "PAY_4                       1.000000  ...   0.240648   0.236905   0.234309   \n",
       "PAY_5                       0.817452  ...   0.265262   0.263856   0.257387   \n",
       "PAY_6                       0.713851  ...   0.262129   0.287259   0.282981   \n",
       "BILL_AMT1                   0.201714  ...   0.861671   0.830888   0.805667   \n",
       "BILL_AMT2                   0.224515  ...   0.892482   0.858302   0.832519   \n",
       "BILL_AMT3                   0.245064  ...   0.931703   0.892319   0.858671   \n",
       "BILL_AMT4                   0.240648  ...   1.000000   0.941142   0.902447   \n",
       "BILL_AMT5                   0.236905  ...   0.941142   1.000000   0.944748   \n",
       "BILL_AMT6                   0.234309  ...   0.902447   0.944748   1.000000   \n",
       "PAY_AMT1                   -0.005518  ...   0.243395   0.227985   0.211163   \n",
       "PAY_AMT2                    0.000193  ...   0.223203   0.199445   0.175053   \n",
       "PAY_AMT3                   -0.069715  ...   0.298209   0.248918   0.230284   \n",
       "PAY_AMT4                   -0.048923  ...   0.138020   0.292033   0.244266   \n",
       "PAY_AMT5                   -0.032754  ...   0.166755   0.149058   0.309427   \n",
       "PAY_AMT6                   -0.028226  ...   0.169249   0.156680   0.105011   \n",
       "default.payment.next.month  0.219692  ...  -0.012313  -0.007868  -0.004944   \n",
       "\n",
       "                            PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  \\\n",
       "ID                          0.013488  0.013389  0.036544  0.010153 -0.000093   \n",
       "LIMIT_BAL                   0.191669  0.183705  0.206416  0.204308  0.215244   \n",
       "SEX                         0.001324  0.000908 -0.008136  0.001473 -0.004470   \n",
       "EDUCATION                  -0.039769 -0.028295 -0.039621 -0.038918 -0.031589   \n",
       "MARRIAGE                   -0.001337 -0.005287 -0.002401 -0.014206 -0.000819   \n",
       "AGE                         0.023255  0.023572  0.034136  0.025197  0.028544   \n",
       "PAY_0                      -0.076790 -0.071744 -0.074217 -0.065880 -0.053086   \n",
       "PAY_2                      -0.076280 -0.057781 -0.055477 -0.052057 -0.033231   \n",
       "PAY_3                       0.002073 -0.068541 -0.054288 -0.052475 -0.035079   \n",
       "PAY_4                      -0.005518  0.000193 -0.069715 -0.048923 -0.032754   \n",
       "PAY_5                      -0.002720  0.000538  0.008884 -0.058547 -0.032159   \n",
       "PAY_6                       0.002340 -0.001092  0.005805  0.016991 -0.045211   \n",
       "BILL_AMT1                   0.146775  0.108425  0.150079  0.150477  0.172609   \n",
       "BILL_AMT2                   0.282783  0.113772  0.146473  0.139343  0.165163   \n",
       "BILL_AMT3                   0.252786  0.285372  0.119375  0.134327  0.171117   \n",
       "BILL_AMT4                   0.243395  0.223203  0.298209  0.138020  0.166755   \n",
       "BILL_AMT5                   0.227985  0.199445  0.248918  0.292033  0.149058   \n",
       "BILL_AMT6                   0.211163  0.175053  0.230284  0.244266  0.309427   \n",
       "PAY_AMT1                    1.000000  0.359611  0.263792  0.217311  0.147038   \n",
       "PAY_AMT2                    0.359611  1.000000  0.268024  0.212814  0.134298   \n",
       "PAY_AMT3                    0.263792  0.268024  1.000000  0.224648  0.142094   \n",
       "PAY_AMT4                    0.217311  0.212814  0.224648  1.000000  0.126775   \n",
       "PAY_AMT5                    0.147038  0.134298  0.142094  0.126775  1.000000   \n",
       "PAY_AMT6                    0.177324  0.173510  0.146699  0.149169  0.141182   \n",
       "default.payment.next.month -0.071563 -0.060730 -0.060868 -0.061005 -0.050943   \n",
       "\n",
       "                            PAY_AMT6  default.payment.next.month  \n",
       "ID                          0.001252                   -0.017861  \n",
       "LIMIT_BAL                   0.215337                   -0.149247  \n",
       "SEX                        -0.001600                   -0.046320  \n",
       "EDUCATION                  -0.038563                    0.026558  \n",
       "MARRIAGE                   -0.007532                   -0.021735  \n",
       "AGE                         0.017527                    0.010715  \n",
       "PAY_0                      -0.063282                    0.325102  \n",
       "PAY_2                      -0.039994                    0.265160  \n",
       "PAY_3                      -0.043431                    0.240503  \n",
       "PAY_4                      -0.028226                    0.219692  \n",
       "PAY_5                      -0.025219                    0.208726  \n",
       "PAY_6                      -0.029144                    0.194787  \n",
       "BILL_AMT1                   0.170210                   -0.020632  \n",
       "BILL_AMT2                   0.169213                   -0.015301  \n",
       "BILL_AMT3                   0.180129                   -0.014718  \n",
       "BILL_AMT4                   0.169249                   -0.012313  \n",
       "BILL_AMT5                   0.156680                   -0.007868  \n",
       "BILL_AMT6                   0.105011                   -0.004944  \n",
       "PAY_AMT1                    0.177324                   -0.071563  \n",
       "PAY_AMT2                    0.173510                   -0.060730  \n",
       "PAY_AMT3                    0.146699                   -0.060868  \n",
       "PAY_AMT4                    0.149169                   -0.061005  \n",
       "PAY_AMT5                    0.141182                   -0.050943  \n",
       "PAY_AMT6                    1.000000                   -0.056093  \n",
       "default.payment.next.month -0.056093                    1.000000  \n",
       "\n",
       "[25 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = train_df.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944748</td>\n",
       "      <td>0.902447</td>\n",
       "      <td>0.858671</td>\n",
       "      <td>0.832519</td>\n",
       "      <td>0.805667</td>\n",
       "      <td>-0.004944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <td>0.944748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941142</td>\n",
       "      <td>0.892319</td>\n",
       "      <td>0.858302</td>\n",
       "      <td>0.830888</td>\n",
       "      <td>-0.007868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <td>0.902447</td>\n",
       "      <td>0.941142</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931703</td>\n",
       "      <td>0.892482</td>\n",
       "      <td>0.861671</td>\n",
       "      <td>-0.012313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <td>0.858671</td>\n",
       "      <td>0.892319</td>\n",
       "      <td>0.931703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938173</td>\n",
       "      <td>0.902255</td>\n",
       "      <td>-0.014718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <td>0.832519</td>\n",
       "      <td>0.858302</td>\n",
       "      <td>0.892482</td>\n",
       "      <td>0.938173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953310</td>\n",
       "      <td>-0.015301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <td>0.805667</td>\n",
       "      <td>0.830888</td>\n",
       "      <td>0.861671</td>\n",
       "      <td>0.902255</td>\n",
       "      <td>0.953310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default.payment.next.month</th>\n",
       "      <td>-0.004944</td>\n",
       "      <td>-0.007868</td>\n",
       "      <td>-0.012313</td>\n",
       "      <td>-0.014718</td>\n",
       "      <td>-0.015301</td>\n",
       "      <td>-0.020632</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            BILL_AMT6  BILL_AMT5  BILL_AMT4  BILL_AMT3  \\\n",
       "BILL_AMT6                    1.000000   0.944748   0.902447   0.858671   \n",
       "BILL_AMT5                    0.944748   1.000000   0.941142   0.892319   \n",
       "BILL_AMT4                    0.902447   0.941142   1.000000   0.931703   \n",
       "BILL_AMT3                    0.858671   0.892319   0.931703   1.000000   \n",
       "BILL_AMT2                    0.832519   0.858302   0.892482   0.938173   \n",
       "BILL_AMT1                    0.805667   0.830888   0.861671   0.902255   \n",
       "default.payment.next.month  -0.004944  -0.007868  -0.012313  -0.014718   \n",
       "\n",
       "                            BILL_AMT2  BILL_AMT1  default.payment.next.month  \n",
       "BILL_AMT6                    0.832519   0.805667                   -0.004944  \n",
       "BILL_AMT5                    0.858302   0.830888                   -0.007868  \n",
       "BILL_AMT4                    0.892482   0.861671                   -0.012313  \n",
       "BILL_AMT3                    0.938173   0.902255                   -0.014718  \n",
       "BILL_AMT2                    1.000000   0.953310                   -0.015301  \n",
       "BILL_AMT1                    0.953310   1.000000                   -0.020632  \n",
       "default.payment.next.month  -0.015301  -0.020632                    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possibly_most_relevant = [\n",
    "    \"BILL_AMT6\",\n",
    "    \"BILL_AMT5\",\n",
    "    \"BILL_AMT4\",\n",
    "    \"BILL_AMT3\",\n",
    "    \"BILL_AMT2\",\n",
    "    \"BILL_AMT1\",\n",
    "    \"default.payment.next.month\",\n",
    "]\n",
    "cor_2 = train_df[possibly_most_relevant].corr()\n",
    "cor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cor_2, annot=True, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features are highly correlated because they are in the same category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 4. Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set in the following exercises. You may have to go back and forth between feature engineering and preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify feature types\n",
    "categorical_features = [\"MARRIAGE\", \"EDUCATION\"]\n",
    "binary_features = [\"SEX\"]\n",
    "drop_features = [\"ID\"]\n",
    "numeric_features = list(\n",
    "    set(train_df.columns)\n",
    "    - set([\"default.payment.next.month\"])\n",
    "    - set(categorical_features)\n",
    "    - set(binary_features)\n",
    "    - set(drop_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Education` is classified as categorical feature because it has 6 levels, of which 3 levels we are unable to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a column transformer\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    OneHotEncoder(drop=\"if_binary\", dtype=int),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                 Pipeline(steps=[('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['BILL_AMT6', 'PAY_6', 'BILL_AMT3', 'PAY_AMT6',\n",
       "                                  'PAY_AMT5', 'PAY_0', 'PAY_5', 'LIMIT_BAL',\n",
       "                                  'PAY_2', 'PAY_4', 'PAY_AMT1', 'BILL_AMT5',\n",
       "                                  'PAY_3', 'BILL_AMT2', 'PAY_AMT2', 'BILL_AMT4',\n",
       "                                  'PAY_AMT3', 'AGE', 'BILL_AMT1', 'PAY_AMT4']),\n",
       "                                ('pipeline-2',\n",
       "                                 Pipeline(steps=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary',\n",
       "                                                                dtype=<class 'int'>))]),\n",
       "                                 ['SEX']),\n",
       "                                ('pipeline-3',\n",
       "                                 Pipeline(steps=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False))]),\n",
       "                                 ['MARRIAGE', 'EDUCATION']),\n",
       "                                ('drop', 'drop', ['ID'])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Transform training set\n",
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** In this part we will use DummyClassifier as the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is adapted from lectures and previous labs:\n",
    "\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.003 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.650 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.217 (+/- 0.015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Dummy\n",
       "fit_time        0.003 (+/- 0.002)\n",
       "score_time      0.005 (+/- 0.001)\n",
       "test_accuracy   0.650 (+/- 0.007)\n",
       "test_f1         0.216 (+/- 0.014)\n",
       "test_recall     0.217 (+/- 0.015)\n",
       "test_precision  0.216 (+/- 0.014)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = [\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
    "dummy_model = DummyClassifier(strategy=\"stratified\")\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(dummy_model, X_train, y_train, scoring=scoring)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test scores are really low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the regularization hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    preprocessor, LogisticRegression(max_iter=1000, random_state=123, class_weight=\"balanced\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11323,  4989],\n",
       "       [ 1658,  3030]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "confusion_matrix(y_train, cross_val_predict(pipe_lr, X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ADD returen train score***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"logistic regression\"] = mean_std_cross_val_scores(\n",
    "    pipe_lr, X_train, y_train, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>logistic regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.003 (+/- 0.002)</td>\n",
       "      <td>0.269 (+/- 0.036)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.650 (+/- 0.007)</td>\n",
       "      <td>0.683 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.477 (+/- 0.009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.217 (+/- 0.015)</td>\n",
       "      <td>0.646 (+/- 0.021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.378 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Dummy logistic regression\n",
       "fit_time        0.003 (+/- 0.002)   0.269 (+/- 0.036)\n",
       "score_time      0.005 (+/- 0.001)   0.007 (+/- 0.000)\n",
       "test_accuracy   0.650 (+/- 0.007)   0.683 (+/- 0.007)\n",
       "test_f1         0.216 (+/- 0.014)   0.477 (+/- 0.009)\n",
       "test_recall     0.217 (+/- 0.015)   0.646 (+/- 0.021)\n",
       "test_precision  0.216 (+/- 0.014)   0.378 (+/- 0.007)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import lognorm, loguniform\n",
    "param_dist = {\"logisticregression__C\": loguniform(1e-3, 1e3)}\n",
    "search = RandomizedSearchCV(\n",
    "    pipe_lr,\n",
    "    param_dist,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    n_iter=50,\n",
    "    return_train_score=True,\n",
    "    scoring=\"f1\",\n",
    "    random_state=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.479834</td>\n",
       "      <td>0.481010</td>\n",
       "      <td>0.01129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.479776</td>\n",
       "      <td>0.481165</td>\n",
       "      <td>0.012444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.479726</td>\n",
       "      <td>0.481897</td>\n",
       "      <td>0.022967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>0.479644</td>\n",
       "      <td>0.481909</td>\n",
       "      <td>0.02342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>0.479108</td>\n",
       "      <td>0.481436</td>\n",
       "      <td>0.031822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>0.478932</td>\n",
       "      <td>0.481068</td>\n",
       "      <td>0.057847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.481011</td>\n",
       "      <td>0.0521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>0.478423</td>\n",
       "      <td>0.480266</td>\n",
       "      <td>0.00494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.478375</td>\n",
       "      <td>0.480761</td>\n",
       "      <td>0.086647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10</td>\n",
       "      <td>0.478322</td>\n",
       "      <td>0.480948</td>\n",
       "      <td>0.074742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11</td>\n",
       "      <td>0.478290</td>\n",
       "      <td>0.480824</td>\n",
       "      <td>0.080115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.478112</td>\n",
       "      <td>0.480528</td>\n",
       "      <td>0.114569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>0.478044</td>\n",
       "      <td>0.480325</td>\n",
       "      <td>0.14816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.477392</td>\n",
       "      <td>0.480222</td>\n",
       "      <td>0.244492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>0.477351</td>\n",
       "      <td>0.480231</td>\n",
       "      <td>0.225271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16</td>\n",
       "      <td>0.477299</td>\n",
       "      <td>0.480258</td>\n",
       "      <td>0.00357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>17</td>\n",
       "      <td>0.477242</td>\n",
       "      <td>0.480199</td>\n",
       "      <td>0.308288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18</td>\n",
       "      <td>0.477095</td>\n",
       "      <td>0.480076</td>\n",
       "      <td>0.358907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.477054</td>\n",
       "      <td>0.479758</td>\n",
       "      <td>15.094374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20</td>\n",
       "      <td>0.477020</td>\n",
       "      <td>0.480127</td>\n",
       "      <td>0.3615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.476976</td>\n",
       "      <td>0.479614</td>\n",
       "      <td>20.740242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>0.476950</td>\n",
       "      <td>0.480081</td>\n",
       "      <td>0.42799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>0.476944</td>\n",
       "      <td>0.480146</td>\n",
       "      <td>0.345652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>0.476940</td>\n",
       "      <td>0.479700</td>\n",
       "      <td>12.852228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.476939</td>\n",
       "      <td>0.479710</td>\n",
       "      <td>21.610275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>26</td>\n",
       "      <td>0.476939</td>\n",
       "      <td>0.479691</td>\n",
       "      <td>462.338553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>0.476902</td>\n",
       "      <td>0.479701</td>\n",
       "      <td>23.67545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.479757</td>\n",
       "      <td>4.635975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0.476895</td>\n",
       "      <td>0.479773</td>\n",
       "      <td>2.031836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>30</td>\n",
       "      <td>0.476881</td>\n",
       "      <td>0.479972</td>\n",
       "      <td>0.791053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>0.476864</td>\n",
       "      <td>0.479663</td>\n",
       "      <td>26.789983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>32</td>\n",
       "      <td>0.476864</td>\n",
       "      <td>0.479664</td>\n",
       "      <td>229.263532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>33</td>\n",
       "      <td>0.476863</td>\n",
       "      <td>0.479670</td>\n",
       "      <td>6.403328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>34</td>\n",
       "      <td>0.476857</td>\n",
       "      <td>0.479748</td>\n",
       "      <td>6.107405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>35</td>\n",
       "      <td>0.476853</td>\n",
       "      <td>0.479797</td>\n",
       "      <td>5.542653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>36</td>\n",
       "      <td>0.476832</td>\n",
       "      <td>0.480087</td>\n",
       "      <td>0.384748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>37</td>\n",
       "      <td>0.476831</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.400135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>0.476827</td>\n",
       "      <td>0.479691</td>\n",
       "      <td>22.219381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39</td>\n",
       "      <td>0.476825</td>\n",
       "      <td>0.479645</td>\n",
       "      <td>124.908147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40</td>\n",
       "      <td>0.476809</td>\n",
       "      <td>0.479782</td>\n",
       "      <td>1.552264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41</td>\n",
       "      <td>0.476805</td>\n",
       "      <td>0.480022</td>\n",
       "      <td>0.768407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>42</td>\n",
       "      <td>0.476787</td>\n",
       "      <td>0.479672</td>\n",
       "      <td>157.708444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>43</td>\n",
       "      <td>0.476781</td>\n",
       "      <td>0.479654</td>\n",
       "      <td>819.141094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>44</td>\n",
       "      <td>0.476768</td>\n",
       "      <td>0.479917</td>\n",
       "      <td>1.025699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>0.479693</td>\n",
       "      <td>766.628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>46</td>\n",
       "      <td>0.476740</td>\n",
       "      <td>0.479805</td>\n",
       "      <td>4.757372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>47</td>\n",
       "      <td>0.476732</td>\n",
       "      <td>0.479896</td>\n",
       "      <td>0.916454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.476729</td>\n",
       "      <td>0.479773</td>\n",
       "      <td>1.308913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49</td>\n",
       "      <td>0.476619</td>\n",
       "      <td>0.479775</td>\n",
       "      <td>1.546352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>0.476151</td>\n",
       "      <td>0.478805</td>\n",
       "      <td>0.002281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  mean_train_score  \\\n",
       "17                1         0.479834          0.481010   \n",
       "16                2         0.479776          0.481165   \n",
       "2                 3         0.479726          0.481897   \n",
       "27                4         0.479644          0.481909   \n",
       "45                5         0.479108          0.481436   \n",
       "28                6         0.478932          0.481068   \n",
       "1                 7         0.478761          0.481011   \n",
       "41                8         0.478423          0.480266   \n",
       "25                9         0.478375          0.480761   \n",
       "35               10         0.478322          0.480948   \n",
       "42               11         0.478290          0.480824   \n",
       "10               12         0.478112          0.480528   \n",
       "26               13         0.478044          0.480325   \n",
       "14               14         0.477392          0.480222   \n",
       "9                15         0.477351          0.480231   \n",
       "30               16         0.477299          0.480258   \n",
       "43               17         0.477242          0.480199   \n",
       "34               18         0.477095          0.480076   \n",
       "0                19         0.477054          0.479758   \n",
       "36               20         0.477020          0.480127   \n",
       "4                21         0.476976          0.479614   \n",
       "12               22         0.476950          0.480081   \n",
       "5                23         0.476944          0.480146   \n",
       "7                24         0.476940          0.479700   \n",
       "24               25         0.476939          0.479710   \n",
       "38               26         0.476939          0.479691   \n",
       "11               27         0.476902          0.479701   \n",
       "23               28         0.476900          0.479757   \n",
       "3                29         0.476895          0.479773   \n",
       "46               30         0.476881          0.479972   \n",
       "15               31         0.476864          0.479663   \n",
       "37               32         0.476864          0.479664   \n",
       "20               33         0.476863          0.479670   \n",
       "29               34         0.476857          0.479748   \n",
       "40               35         0.476853          0.479797   \n",
       "32               36         0.476832          0.480087   \n",
       "31               37         0.476831          0.480000   \n",
       "22               38         0.476827          0.479691   \n",
       "21               39         0.476825          0.479645   \n",
       "19               40         0.476809          0.479782   \n",
       "8                41         0.476805          0.480022   \n",
       "44               42         0.476787          0.479672   \n",
       "47               43         0.476781          0.479654   \n",
       "39               44         0.476768          0.479917   \n",
       "6                45         0.476744          0.479693   \n",
       "49               46         0.476740          0.479805   \n",
       "33               47         0.476732          0.479896   \n",
       "48               48         0.476729          0.479773   \n",
       "18               49         0.476619          0.479775   \n",
       "13               50         0.476151          0.478805   \n",
       "\n",
       "   param_logisticregression__C  \n",
       "17                     0.01129  \n",
       "16                    0.012444  \n",
       "2                     0.022967  \n",
       "27                     0.02342  \n",
       "45                    0.031822  \n",
       "28                    0.057847  \n",
       "1                       0.0521  \n",
       "41                     0.00494  \n",
       "25                    0.086647  \n",
       "35                    0.074742  \n",
       "42                    0.080115  \n",
       "10                    0.114569  \n",
       "26                     0.14816  \n",
       "14                    0.244492  \n",
       "9                     0.225271  \n",
       "30                     0.00357  \n",
       "43                    0.308288  \n",
       "34                    0.358907  \n",
       "0                    15.094374  \n",
       "36                      0.3615  \n",
       "4                    20.740242  \n",
       "12                     0.42799  \n",
       "5                     0.345652  \n",
       "7                    12.852228  \n",
       "24                   21.610275  \n",
       "38                  462.338553  \n",
       "11                    23.67545  \n",
       "23                    4.635975  \n",
       "3                     2.031836  \n",
       "46                    0.791053  \n",
       "15                   26.789983  \n",
       "37                  229.263532  \n",
       "20                    6.403328  \n",
       "29                    6.107405  \n",
       "40                    5.542653  \n",
       "32                    0.384748  \n",
       "31                    0.400135  \n",
       "22                   22.219381  \n",
       "21                  124.908147  \n",
       "19                    1.552264  \n",
       "8                     0.768407  \n",
       "44                  157.708444  \n",
       "47                  819.141094  \n",
       "39                    1.025699  \n",
       "6                   766.628906  \n",
       "49                    4.757372  \n",
       "33                    0.916454  \n",
       "48                    1.308913  \n",
       "18                    1.546352  \n",
       "13                    0.002281  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df = pd.DataFrame(search.cv_results_)[\n",
    "    [\n",
    "        \"rank_test_score\",\n",
    "        \"mean_test_score\",\n",
    "        \"mean_train_score\",\n",
    "        \"param_logisticregression__C\",\n",
    "    ]\n",
    "]\n",
    "search_df = search_df.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters found by our random search are: C = 0.01129 with a validation f1-score of 0.479."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"tuned logistic regression\"] = mean_std_cross_val_scores(\n",
    "    best_lr, X_train, y_train, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>tuned logistic regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.003 (+/- 0.002)</td>\n",
       "      <td>0.269 (+/- 0.036)</td>\n",
       "      <td>0.092 (+/- 0.029)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.008 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.650 (+/- 0.007)</td>\n",
       "      <td>0.683 (+/- 0.007)</td>\n",
       "      <td>0.689 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.477 (+/- 0.009)</td>\n",
       "      <td>0.480 (+/- 0.009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.217 (+/- 0.015)</td>\n",
       "      <td>0.646 (+/- 0.021)</td>\n",
       "      <td>0.642 (+/- 0.021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.378 (+/- 0.007)</td>\n",
       "      <td>0.383 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Dummy logistic regression  \\\n",
       "fit_time        0.003 (+/- 0.002)   0.269 (+/- 0.036)   \n",
       "score_time      0.005 (+/- 0.001)   0.007 (+/- 0.000)   \n",
       "test_accuracy   0.650 (+/- 0.007)   0.683 (+/- 0.007)   \n",
       "test_f1         0.216 (+/- 0.014)   0.477 (+/- 0.009)   \n",
       "test_recall     0.217 (+/- 0.015)   0.646 (+/- 0.021)   \n",
       "test_precision  0.216 (+/- 0.014)   0.378 (+/- 0.007)   \n",
       "\n",
       "               tuned logistic regression  \n",
       "fit_time               0.092 (+/- 0.029)  \n",
       "score_time             0.008 (+/- 0.000)  \n",
       "test_accuracy          0.689 (+/- 0.007)  \n",
       "test_f1                0.480 (+/- 0.009)  \n",
       "test_recall            0.642 (+/- 0.021)  \n",
       "test_precision         0.383 (+/- 0.008)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Different models <a name=\"8\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:10,reasoning:6}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from a linear model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(random_state=123, n_jobs=-1, class_weight=\"balanced\")\n",
    ")\n",
    "pipe_svc = make_pipeline(\n",
    "    preprocessor, SVC(class_weight=\"balanced\")\n",
    ")\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(random_state=123, class_weight=\"balanced\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"random forest\": pipe_rf,\n",
    "    \"SVC\": pipe_svc,\n",
    "    \"LGBMC\": pipe_lgbm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, model) in models.items():\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>tuned logistic regression</th>\n",
       "      <th>random forest</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LGBMC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.003 (+/- 0.002)</td>\n",
       "      <td>0.269 (+/- 0.036)</td>\n",
       "      <td>0.092 (+/- 0.029)</td>\n",
       "      <td>0.954 (+/- 0.505)</td>\n",
       "      <td>10.570 (+/- 0.073)</td>\n",
       "      <td>0.208 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.008 (+/- 0.000)</td>\n",
       "      <td>0.044 (+/- 0.009)</td>\n",
       "      <td>5.346 (+/- 0.255)</td>\n",
       "      <td>0.014 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.650 (+/- 0.007)</td>\n",
       "      <td>0.683 (+/- 0.007)</td>\n",
       "      <td>0.689 (+/- 0.007)</td>\n",
       "      <td>0.815 (+/- 0.004)</td>\n",
       "      <td>0.781 (+/- 0.011)</td>\n",
       "      <td>0.765 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.477 (+/- 0.009)</td>\n",
       "      <td>0.480 (+/- 0.009)</td>\n",
       "      <td>0.455 (+/- 0.009)</td>\n",
       "      <td>0.542 (+/- 0.016)</td>\n",
       "      <td>0.539 (+/- 0.013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.378 (+/- 0.007)</td>\n",
       "      <td>0.383 (+/- 0.008)</td>\n",
       "      <td>0.664 (+/- 0.023)</td>\n",
       "      <td>0.509 (+/- 0.021)</td>\n",
       "      <td>0.480 (+/- 0.012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.217 (+/- 0.015)</td>\n",
       "      <td>0.646 (+/- 0.021)</td>\n",
       "      <td>0.642 (+/- 0.021)</td>\n",
       "      <td>0.346 (+/- 0.009)</td>\n",
       "      <td>0.580 (+/- 0.009)</td>\n",
       "      <td>0.615 (+/- 0.014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.791 (+/- 0.001)</td>\n",
       "      <td>0.824 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.565 (+/- 0.002)</td>\n",
       "      <td>0.664 (+/- 0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997 (+/- 0.000)</td>\n",
       "      <td>0.528 (+/- 0.003)</td>\n",
       "      <td>0.580 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.609 (+/- 0.002)</td>\n",
       "      <td>0.775 (+/- 0.009)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dummy logistic regression  \\\n",
       "fit_time         0.003 (+/- 0.002)   0.269 (+/- 0.036)   \n",
       "score_time       0.005 (+/- 0.001)   0.007 (+/- 0.000)   \n",
       "test_accuracy    0.650 (+/- 0.007)   0.683 (+/- 0.007)   \n",
       "test_f1          0.216 (+/- 0.014)   0.477 (+/- 0.009)   \n",
       "test_precision   0.216 (+/- 0.014)   0.378 (+/- 0.007)   \n",
       "test_recall      0.217 (+/- 0.015)   0.646 (+/- 0.021)   \n",
       "train_accuracy                 NaN                 NaN   \n",
       "train_f1                       NaN                 NaN   \n",
       "train_precision                NaN                 NaN   \n",
       "train_recall                   NaN                 NaN   \n",
       "\n",
       "                tuned logistic regression      random forest  \\\n",
       "fit_time                0.092 (+/- 0.029)  0.954 (+/- 0.505)   \n",
       "score_time              0.008 (+/- 0.000)  0.044 (+/- 0.009)   \n",
       "test_accuracy           0.689 (+/- 0.007)  0.815 (+/- 0.004)   \n",
       "test_f1                 0.480 (+/- 0.009)  0.455 (+/- 0.009)   \n",
       "test_precision          0.383 (+/- 0.008)  0.664 (+/- 0.023)   \n",
       "test_recall             0.642 (+/- 0.021)  0.346 (+/- 0.009)   \n",
       "train_accuracy                        NaN  0.999 (+/- 0.000)   \n",
       "train_f1                              NaN  0.999 (+/- 0.000)   \n",
       "train_precision                       NaN  0.997 (+/- 0.000)   \n",
       "train_recall                          NaN  1.000 (+/- 0.000)   \n",
       "\n",
       "                                SVC              LGBMC  \n",
       "fit_time         10.570 (+/- 0.073)  0.208 (+/- 0.007)  \n",
       "score_time        5.346 (+/- 0.255)  0.014 (+/- 0.000)  \n",
       "test_accuracy     0.781 (+/- 0.011)  0.765 (+/- 0.007)  \n",
       "test_f1           0.542 (+/- 0.016)  0.539 (+/- 0.013)  \n",
       "test_precision    0.509 (+/- 0.021)  0.480 (+/- 0.012)  \n",
       "test_recall       0.580 (+/- 0.009)  0.615 (+/- 0.014)  \n",
       "train_accuracy    0.791 (+/- 0.001)  0.824 (+/- 0.003)  \n",
       "train_f1          0.565 (+/- 0.002)  0.664 (+/- 0.004)  \n",
       "train_precision   0.528 (+/- 0.003)  0.580 (+/- 0.005)  \n",
       "train_recall      0.609 (+/- 0.002)  0.775 (+/- 0.009)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarize Results:**\n",
    "- `SVC` returns the best f1 score of 0.542, while `random forest` returns lower f1 score than logistic regression.\n",
    "- random forest overfitting, others underfitting\n",
    "- fit time, score time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. You may try `RFECV`, forward selection or L1 regularization for this. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it in the next exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Optimize hyperparameters for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_1 = {\n",
    "    \"svc__C\": [0.01, 0.1, 1.0, 10, 100],\n",
    "    \"svc__gamma\": [0.01, 0.1, 1.0, 10, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1 = RandomizedSearchCV(\n",
    "    pipe_svc,\n",
    "    param_dist_1,\n",
    "    #verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    #n_iter=50,\n",
    "    return_train_score=True,\n",
    "    scoring=\"f1\",\n",
    "    random_state=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.538227</td>\n",
       "      <td>0.556545</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.537540</td>\n",
       "      <td>0.593789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.524077</td>\n",
       "      <td>0.526575</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.439892</td>\n",
       "      <td>0.800800</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.415610</td>\n",
       "      <td>0.444618</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.366193</td>\n",
       "      <td>0.370912</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0.364995</td>\n",
       "      <td>0.364995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0.364995</td>\n",
       "      <td>0.364995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.298270</td>\n",
       "      <td>0.971113</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.088663</td>\n",
       "      <td>0.991985</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  mean_train_score param_svc__C  \\\n",
       "4                1         0.538227          0.556545           10   \n",
       "7                2         0.537540          0.593789          1.0   \n",
       "0                3         0.524077          0.526575          0.1   \n",
       "1                4         0.439892          0.800800          100   \n",
       "6                5         0.415610          0.444618          0.1   \n",
       "5                6         0.366193          0.370912          0.1   \n",
       "8                7         0.364995          0.364995         0.01   \n",
       "9                7         0.364995          0.364995         0.01   \n",
       "2                9         0.298270          0.971113          100   \n",
       "3               10         0.088663          0.991985           10   \n",
       "\n",
       "  param_svc__gamma  \n",
       "4             0.01  \n",
       "7              0.1  \n",
       "0             0.01  \n",
       "1              0.1  \n",
       "6              1.0  \n",
       "5               10  \n",
       "8              100  \n",
       "9               10  \n",
       "2              1.0  \n",
       "3               10  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df = pd.DataFrame(search_1.cv_results_)[\n",
    "    [\n",
    "        \"rank_test_score\",\n",
    "        \"mean_test_score\",\n",
    "        \"mean_train_score\",\n",
    "        \"param_svc__C\",\n",
    "        \"param_svc__gamma\",\n",
    "    ]\n",
    "]\n",
    "search_df = search_df.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters found by our random search are: C = 0.01129 with a validation f1-score of 0.479."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc = search_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Tuned SVC\"] = mean_std_cross_val_scores(\n",
    "    best_svc, X_train, y_train, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>tuned logistic regression</th>\n",
       "      <th>random forest</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LGBMC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.003 (+/- 0.002)</td>\n",
       "      <td>0.269 (+/- 0.036)</td>\n",
       "      <td>11.256 (+/- 0.207)</td>\n",
       "      <td>0.954 (+/- 0.505)</td>\n",
       "      <td>10.570 (+/- 0.073)</td>\n",
       "      <td>0.208 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>5.525 (+/- 0.255)</td>\n",
       "      <td>0.044 (+/- 0.009)</td>\n",
       "      <td>5.346 (+/- 0.255)</td>\n",
       "      <td>0.014 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.650 (+/- 0.007)</td>\n",
       "      <td>0.683 (+/- 0.007)</td>\n",
       "      <td>0.778 (+/- 0.008)</td>\n",
       "      <td>0.815 (+/- 0.004)</td>\n",
       "      <td>0.781 (+/- 0.011)</td>\n",
       "      <td>0.765 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.477 (+/- 0.009)</td>\n",
       "      <td>0.538 (+/- 0.010)</td>\n",
       "      <td>0.455 (+/- 0.009)</td>\n",
       "      <td>0.542 (+/- 0.016)</td>\n",
       "      <td>0.539 (+/- 0.013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.216 (+/- 0.014)</td>\n",
       "      <td>0.378 (+/- 0.007)</td>\n",
       "      <td>0.502 (+/- 0.015)</td>\n",
       "      <td>0.664 (+/- 0.023)</td>\n",
       "      <td>0.509 (+/- 0.021)</td>\n",
       "      <td>0.480 (+/- 0.012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.217 (+/- 0.015)</td>\n",
       "      <td>0.646 (+/- 0.021)</td>\n",
       "      <td>0.580 (+/- 0.010)</td>\n",
       "      <td>0.346 (+/- 0.009)</td>\n",
       "      <td>0.580 (+/- 0.009)</td>\n",
       "      <td>0.615 (+/- 0.014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.791 (+/- 0.001)</td>\n",
       "      <td>0.824 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.565 (+/- 0.002)</td>\n",
       "      <td>0.664 (+/- 0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997 (+/- 0.000)</td>\n",
       "      <td>0.528 (+/- 0.003)</td>\n",
       "      <td>0.580 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.609 (+/- 0.002)</td>\n",
       "      <td>0.775 (+/- 0.009)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dummy logistic regression  \\\n",
       "fit_time         0.003 (+/- 0.002)   0.269 (+/- 0.036)   \n",
       "score_time       0.005 (+/- 0.001)   0.007 (+/- 0.000)   \n",
       "test_accuracy    0.650 (+/- 0.007)   0.683 (+/- 0.007)   \n",
       "test_f1          0.216 (+/- 0.014)   0.477 (+/- 0.009)   \n",
       "test_precision   0.216 (+/- 0.014)   0.378 (+/- 0.007)   \n",
       "test_recall      0.217 (+/- 0.015)   0.646 (+/- 0.021)   \n",
       "train_accuracy                 NaN                 NaN   \n",
       "train_f1                       NaN                 NaN   \n",
       "train_precision                NaN                 NaN   \n",
       "train_recall                   NaN                 NaN   \n",
       "\n",
       "                tuned logistic regression      random forest  \\\n",
       "fit_time               11.256 (+/- 0.207)  0.954 (+/- 0.505)   \n",
       "score_time              5.525 (+/- 0.255)  0.044 (+/- 0.009)   \n",
       "test_accuracy           0.778 (+/- 0.008)  0.815 (+/- 0.004)   \n",
       "test_f1                 0.538 (+/- 0.010)  0.455 (+/- 0.009)   \n",
       "test_precision          0.502 (+/- 0.015)  0.664 (+/- 0.023)   \n",
       "test_recall             0.580 (+/- 0.010)  0.346 (+/- 0.009)   \n",
       "train_accuracy                        NaN  0.999 (+/- 0.000)   \n",
       "train_f1                              NaN  0.999 (+/- 0.000)   \n",
       "train_precision                       NaN  0.997 (+/- 0.000)   \n",
       "train_recall                          NaN  1.000 (+/- 0.000)   \n",
       "\n",
       "                                SVC              LGBMC  \n",
       "fit_time         10.570 (+/- 0.073)  0.208 (+/- 0.007)  \n",
       "score_time        5.346 (+/- 0.255)  0.014 (+/- 0.000)  \n",
       "test_accuracy     0.781 (+/- 0.011)  0.765 (+/- 0.007)  \n",
       "test_f1           0.542 (+/- 0.016)  0.539 (+/- 0.013)  \n",
       "test_precision    0.509 (+/- 0.021)  0.480 (+/- 0.012)  \n",
       "test_recall       0.580 (+/- 0.009)  0.615 (+/- 0.014)  \n",
       "train_accuracy    0.791 (+/- 0.001)  0.824 (+/- 0.003)  \n",
       "train_f1          0.565 (+/- 0.002)  0.664 (+/- 0.004)  \n",
       "train_precision   0.528 (+/- 0.003)  0.580 (+/- 0.005)  \n",
       "train_recall      0.609 (+/- 0.002)  0.775 (+/- 0.009)  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Optimize hyperparameters for LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_2 = {\n",
    "    \"__C\": [0.01, 0.1, 1.0, 10, 100],\n",
    "    \"svc__gamma\": [0.01, 0.1, 1.0, 10, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_2 = RandomizedSearchCV(\n",
    "    pipe_lgbm,\n",
    "    param_dist_2,\n",
    "    #verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    #n_iter=50,\n",
    "    return_train_score=True,\n",
    "    scoring=\"f1\",\n",
    "    random_state=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df = pd.DataFrame(search_1.cv_results_)[\n",
    "    [\n",
    "        \"rank_test_score\",\n",
    "        \"mean_test_score\",\n",
    "        \"mean_train_score\",\n",
    "        \"param_svc__C\",\n",
    "        \"param_svc__gamma\",\n",
    "    ]\n",
    "]\n",
    "search_df = search_df.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_3 = {\"randomforestclassifier__n_estimators\": np.arange(1, 20, 2)}\n",
    "search_3 = RandomizedSearchCV(\n",
    "    pipe_rf,\n",
    "    param_dist_3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    n_iter=50,\n",
    "    return_train_score=True,\n",
    "    scoring=\"f1\",\n",
    "    random_state=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "search_3.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.448167</td>\n",
       "      <td>0.987194</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.447640</td>\n",
       "      <td>0.985205</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444998</td>\n",
       "      <td>0.981599</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.444844</td>\n",
       "      <td>0.977064</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.440841</td>\n",
       "      <td>0.972478</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.439178</td>\n",
       "      <td>0.965301</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.436152</td>\n",
       "      <td>0.954566</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.434264</td>\n",
       "      <td>0.934094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.415407</td>\n",
       "      <td>0.890801</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.380834</td>\n",
       "      <td>0.783214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  mean_train_score  \\\n",
       "9                1         0.448167          0.987194   \n",
       "8                2         0.447640          0.985205   \n",
       "7                3         0.444998          0.981599   \n",
       "6                4         0.444844          0.977064   \n",
       "5                5         0.440841          0.972478   \n",
       "4                6         0.439178          0.965301   \n",
       "3                7         0.436152          0.954566   \n",
       "2                8         0.434264          0.934094   \n",
       "1                9         0.415407          0.890801   \n",
       "0               10         0.380834          0.783214   \n",
       "\n",
       "  param_randomforestclassifier__n_estimators  \n",
       "9                                         19  \n",
       "8                                         17  \n",
       "7                                         15  \n",
       "6                                         13  \n",
       "5                                         11  \n",
       "4                                          9  \n",
       "3                                          7  \n",
       "2                                          5  \n",
       "1                                          3  \n",
       "0                                          1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df_3 = pd.DataFrame(search_3.cv_results_)[\n",
    "    [\n",
    "        \"rank_test_score\",\n",
    "        \"mean_test_score\",\n",
    "        \"mean_train_score\",\n",
    "        \"param_randomforestclassifier__n_estimators\",\n",
    "    ]\n",
    "]\n",
    "search_df_3 = search_df_3.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "search_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = search_3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"tuned logistic regression\"] = mean_std_cross_val_scores(\n",
    "    best_lr, X_train, y_train, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interpretation and feature importances <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`), or any other methods of your choice, to examine the most important features of one of the non-linear models. \n",
    "2. Summarize your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? \n",
    "3. Take one or two test predictions and explain them with SHAP force plots.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:12}\n",
    "\n",
    "Imagine that you want to present the summary of these results to your boss and co-workers. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a table summarizing important results. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . \n",
    "3. Report your final test score along with the metric you used at the top of this notebook in the [Submission instructions section](#si)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 14. Creating a data analysis pipeline <a name=\"14\"></a>\n",
    "rubric={reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "- In 522 you learned how build a reproducible data analysis pipeline. Convert this notebook into scripts and create a reproducible data analysis pipeline with appropriate documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 15. Your takeaway from the course <a name=\"15\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from this course? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** \n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Push all your work to your GitHub lab repository. \n",
    "4. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "5. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done!! Have a great weekend! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"eva-well-done.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
